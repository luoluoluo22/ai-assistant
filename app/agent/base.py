"""Base agent for handling user requests."""

import sys
import json
import logging
import uuid
import time
from typing import Dict, Any, List, Optional, AsyncGenerator
from ..services.ai_tool_service import AIToolService
from ..core.config import settings
from ..core.prompts import generate_system_prompt, generate_base_system_prompt, generate_result_summary_prompt
from ..tools.manager import ToolManager

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

class Agent:
    """Base agent class for handling user requests."""
    
    def __init__(self):
        """Initialize the agent."""
        self.tool_service = AIToolService()
        self.tool_manager = ToolManager()
        self.context = {
            "conversation_history": [],
            "tool_results": [],
            "memory": {},
            "os": sys.platform
        }
        self.system_prompt = generate_system_prompt()
        logger.info("Agent initialized with system prompt:\n%s", self.system_prompt)
    
    async def process_message(
        self,
        message: str,
        model: str = settings.DEFAULT_MODEL,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None,
        top_p: float = 0.95,
        frequency_penalty: float = 0.0,
        presence_penalty: float = 0.0,
        stream: bool = False
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """Process user message and return response.
        
        Args:
            message: User's natural language input
            model: Model to use for generation
            temperature: Sampling temperature
            max_tokens: Maximum tokens to generate
            top_p: Nucleus sampling threshold
            frequency_penalty: Frequency penalty
            presence_penalty: Presence penalty
            stream: Whether to stream the response
            
        Returns:
            Agent's response
        """
        # 1. æ›´æ–°å¯¹è¯å†å²
        self.context["conversation_history"].append({
            "role": "user",
            "content": message
        })
        
        # 2. å¤„ç†ç”¨æˆ·æ¶ˆæ¯å¹¶æ‰§è¡Œå·¥å…·è°ƒç”¨
        logger.info("Processing message: %s", message)
        current_message = message
        all_results = []
        max_iterations = 10  # é˜²æ­¢æ— é™å¾ªç¯
        iteration_count = 0
        
        while iteration_count < max_iterations:
            iteration_count += 1
            logger.info(f"Iteration {iteration_count} of {max_iterations}")
            
            # å‘é€æ­£åœ¨æ€è€ƒçš„æç¤º
            yield {
                "type": "thinking",
                "content": "AIæ­£åœ¨æ€è€ƒ..."
            }
            
            # è·å–æ¨¡å‹å“åº”
            response = await self.tool_service.chat_completion(
                current_message,
                system_prompt=self.system_prompt,
                model=model,
                temperature=temperature,
                max_tokens=max_tokens,
                top_p=top_p,
                frequency_penalty=frequency_penalty,
                presence_penalty=presence_penalty
            )
            
            logger.info("AI å“åº”:\n%s", response)
            
            # å°è¯•ä»å“åº”ä¸­æå–å·¥å…·è°ƒç”¨
            tool_call = self._extract_tool_call(response)
            
            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨æˆ–è€…æ˜¯ä»»åŠ¡å®Œæˆå·¥å…·ï¼Œç»“æŸå¾ªç¯
            if not tool_call or tool_call.get("tool_name") == "task_complete":
                break
            
            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            logger.info("Executing tool: %s", json.dumps(tool_call, ensure_ascii=False))
            result = await self._execute_step(tool_call)
            all_results.append(result)
            
            # æ›´æ–°å·¥å…·æ‰§è¡Œç»“æœå†å²
            self.context["tool_results"].append({
                "step": tool_call,
                "result": result
            })
            
            # å°†æ‰§è¡Œç»“æœæ ¼å¼åŒ–ä¸ºæ˜“äºç†è§£çš„å½¢å¼
            result_summary = self._format_step_result(tool_call, result)
            
            # æ›´æ–°å½“å‰æ¶ˆæ¯ï¼ŒåŒ…å«æ‰§è¡Œç»“æœ
            current_message = f"{message}\n\nå·²æ‰§è¡Œå·¥å…·ï¼š\n{json.dumps(tool_call, ensure_ascii=False)}\n\næ‰§è¡Œç»“æœï¼š\n{result_summary}\n\nè¯·æ ¹æ®ä»¥ä¸Šç»“æœç»§ç»­å›ç­”æˆ–æ‰§è¡Œä¸‹ä¸€ä¸ªå·¥å…·ã€‚å¦‚æœä»»åŠ¡å·²å®Œæˆï¼Œè¯·ç›´æ¥å›ç­”ï¼Œä¸è¦è°ƒç”¨å·¥å…·ã€‚"
        
        # 3. ç”Ÿæˆæœ€ç»ˆå“åº”
        final_response = await self._generate_response(
            message,
            all_results,
            model=model,
            temperature=temperature,
            max_tokens=max_tokens,
            top_p=top_p,
            frequency_penalty=frequency_penalty,
            presence_penalty=presence_penalty,
            stream=stream
        )
        
        # 4. æ›´æ–°å¯¹è¯å†å²
        self.context["conversation_history"].append({
            "role": "assistant",
            "content": final_response
        })
        
        yield {
            "type": "response",
            "content": final_response
        }
    
    
    async def _execute_step(self, step: Dict[str, Any]) -> Dict[str, Any]:
        """Execute a single step in the plan.
        
        Args:
            step: Step to execute
            
        Returns:
            Result of tool execution
        """
        try:
            # è®°å½•æ‰§è¡Œè®¡åˆ’
            logger.info("ç”Ÿæˆçš„æ‰§è¡Œè®¡åˆ’:\n%s", json.dumps(step, ensure_ascii=False, indent=2))
            
            # éªŒè¯å·¥å…·è¯·æ±‚
            errors = self.tool_service.validate_tool_request(step)
            if errors:
                error_msg = f"å·¥å…·è¯·æ±‚éªŒè¯å¤±è´¥: {', '.join(errors)}"
                logger.error(error_msg)
                return {
                    "status": "error",
                    "message": error_msg
                }
            
            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            result = await self.tool_service.execute_tool(step)
            
            # è®°å½•æ‰§è¡Œç»“æœ
            logger.debug("å·¥å…·æ‰§è¡Œç»“æœ:\n%s", json.dumps(result, ensure_ascii=False, indent=2))
            
            return result
            
        except Exception as e:
            error_msg = f"Tool execution failed: {str(e)}"
            logger.error(error_msg, exc_info=True)
            return {
                "status": "error",
                "message": error_msg
            }
    
    async def _generate_response(
        self,
        message: str,
        results: List[Dict[str, Any]],
        model: str = settings.DEFAULT_MODEL,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None,
        top_p: float = 0.95,
        frequency_penalty: float = 0.0,
        presence_penalty: float = 0.0,
        stream: bool = False
    ) -> str:
        """Generate a natural language response."""
        try:
            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = generate_result_summary_prompt()

            # æ„å»ºç”¨æˆ·æç¤ºè¯
            user_prompt = f"ç”¨æˆ·é—®é¢˜ï¼š{message}\n\n"
            
            if results:
                user_prompt += "å·¥å…·æ‰§è¡Œç»“æœï¼š\n"
                for result in results:
                    # å¤„ç†ç½‘é¡µæœç´¢ç»“æœ
                    if isinstance(result.get("data"), dict) and "results" in result["data"]:
                        web_results = result["data"]["results"]
                        if web_results:
                            user_prompt += "\næœç´¢ç»“æœï¼š\n"
                            for item in web_results:
                                title = item.get("title", "")
                                url = item.get("url", "")
                                content = item.get("content", "")
                                if content and len(content) > 1000:  # é™åˆ¶æ¯ä¸ªç»“æœçš„å†…å®¹é•¿åº¦
                                    content = content[:1000] + "...(å†…å®¹å·²æˆªæ–­)"
                                user_prompt += f"\næ ‡é¢˜ï¼š{title}\né“¾æ¥ï¼š{url}\nå†…å®¹ï¼š{content}\n"
                    else:
                        result_str = json.dumps(result, ensure_ascii=False, indent=2)
                        if len(result_str) > 10000:  # é™åˆ¶ç»“æœé•¿åº¦
                            result_str = result_str[:10000] + "...(ç»“æœå·²æˆªæ–­)"
                        user_prompt += result_str + "\n\n"
            else:
                user_prompt += "æ²¡æœ‰æ‰§è¡Œä»»ä½•å·¥å…·ã€‚\n"
            
            # è°ƒç”¨ AI æœåŠ¡ç”Ÿæˆå›å¤
            response = await self.tool_service.chat_completion(
                user_prompt,
                system_prompt=system_prompt,  # æ·»åŠ ç³»ç»Ÿæç¤ºè¯
                model=model,
                temperature=0.2,  # ä½¿ç”¨è¾ƒä½çš„æ¸©åº¦ä»¥è·å¾—æ›´ç¡®å®šçš„å›ç­”
                max_tokens=max_tokens,
                top_p=top_p,
                frequency_penalty=frequency_penalty,
                presence_penalty=presence_penalty
            )
            
            return response.strip()
            
        except Exception as e:
            logger.error("ç”Ÿæˆå›å¤å¤±è´¥: %s", str(e), exc_info=True)
            return f"ç”Ÿæˆå›å¤æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
    
    def update_memory(self, key: str, value: Any):
        """Update agent's memory.
        
        Args:
            key: Memory key
            value: Memory value
        """
        self.context["memory"][key] = value
    
    def get_memory(self, key: str) -> Optional[Any]:
        """Get value from agent's memory.
        
        Args:
            key: Memory key
            
        Returns:
            Stored value or None if not found
        """
        return self.context["memory"].get(key)
    
    def clear_memory(self):
        """Clear agent's memory."""
        self.context["memory"].clear()

    async def stream_message(
        self,
        message: str,
        model: str = settings.DEFAULT_MODEL,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None,
        top_p: float = 0.95,
        frequency_penalty: float = 0.0,
        presence_penalty: float = 0.0
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """Stream process user message and yield response chunks."""
        try:
            # 1. æ›´æ–°å¯¹è¯å†å²
            self.context["conversation_history"].append({
                "role": "user",
                "content": message
            })
            
            # 2. å¤„ç†ç”¨æˆ·æ„å›¾å’Œç”Ÿæˆæ‰§è¡Œè®¡åˆ’
            logger.info("Processing message: %s", message)
            current_message = message
            all_results = []
            max_iterations = 10  # é˜²æ­¢æ— é™å¾ªç¯
            iteration_count = 0
            
            while iteration_count < max_iterations:
                iteration_count += 1
                logger.info(f"Iteration {iteration_count} of {max_iterations}")
                
                # å‘é€æ­£åœ¨æ€è€ƒçš„æç¤º
                yield {
                    "type": "thinking",
                    "content": "\nğŸ¤” AIæ­£åœ¨æ€è€ƒ...\n"
                }
                
                # è·å–æ¨¡å‹å“åº”
                response = await self.tool_service.chat_completion(
                    current_message,
                    system_prompt=self.system_prompt,
                    model=model,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    top_p=top_p,
                    frequency_penalty=frequency_penalty,
                    presence_penalty=presence_penalty
                )
                
                logger.info("AI å“åº”:\n%s", response)
                
                # å°è¯•ä»å“åº”ä¸­æå–å·¥å…·è°ƒç”¨
                tool_call = self._extract_tool_call(response)
                
                # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸå¾ªç¯
                if not tool_call:
                    break

                # å‘é€æ­£åœ¨æ‰§è¡Œçš„æ­¥éª¤ä¿¡æ¯
                tool_info = f"\nğŸ”§ æ‰§è¡Œå·¥å…·: {tool_call['tool_name']}\n"
                tool_info += "ğŸ“ å‚æ•°:\n```json\n"
                tool_info += json.dumps(tool_call.get('parameters', {}), ensure_ascii=False, indent=2)
                tool_info += "\n```\n"
                yield {
                    "type": "step_start",
                    "content": tool_info
                }
                
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                logger.info("Executing tool: %s", json.dumps(tool_call, ensure_ascii=False))
                result = await self._execute_step(tool_call)
                all_results.append(result)
                
                # æ›´æ–°å·¥å…·æ‰§è¡Œç»“æœå†å²
                self.context["tool_results"].append({
                    "step": tool_call,
                    "result": result
                })
                
                # å¤„ç†å·¥å…·æ‰§è¡Œç»“æœ
                if isinstance(result, dict):
                    # ä¿®æ”¹é”™è¯¯åˆ¤æ–­é€»è¾‘
                    has_error = False
                    if result.get("status") == "error":
                        has_error = True
                    elif result.get("return_code", 0) != 0:
                        has_error = True
                    elif tool_call['tool_name'] == 'email' and result.get('success') is False:
                        has_error = True
                    
                    if has_error:
                        error_message = result.get("message", "æœªçŸ¥é”™è¯¯")
                        yield {
                            "type": "error",
                            "content": f"\nâŒ é”™è¯¯:\n{error_message}\n"
                        }
                        # å¦‚æœæ˜¯åˆ é™¤é‚®ä»¶å¤±è´¥ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€å°
                        if tool_call['tool_name'] == 'email' and tool_call.get('parameters', {}).get('action') == 'delete_email':
                            continue
                        break
                    
                    # æ ¼å¼åŒ–ç»“æœ
                    formatted_result = self._format_step_result(tool_call, result)
                    if formatted_result.strip():
                        yield {
                            "type": "step_result",
                            "content": f"\nâœ… æ‰§è¡Œç»“æœ:\n{formatted_result}\n"
                        }
                elif isinstance(result, str):
                    if result.strip():
                        yield {
                            "type": "step_result",
                            "content": f"\nâœ… æ‰§è¡Œç»“æœ:\n{result}\n"
                        }
                
                # å°†æ‰§è¡Œç»“æœæ ¼å¼åŒ–ä¸ºæ˜“äºç†è§£çš„å½¢å¼
                result_summary = self._format_step_result(tool_call, result)
                
                # æ›´æ–°å½“å‰æ¶ˆæ¯ï¼ŒåŒ…å«æ‰§è¡Œç»“æœ
                current_message = f"{message}\n\nå·²æ‰§è¡Œå·¥å…·ï¼š\n{json.dumps(tool_call, ensure_ascii=False)}\n\næ‰§è¡Œç»“æœï¼š\n{result_summary}\n\nè¯·æ ¹æ®ä»¥ä¸Šç»“æœç»§ç»­å›ç­”æˆ–æ‰§è¡Œä¸‹ä¸€ä¸ªå·¥å…·ã€‚å¦‚æœä»»åŠ¡å·²å®Œæˆï¼Œè¯·ç›´æ¥å›ç­”ï¼Œä¸è¦è°ƒç”¨å·¥å…·ã€‚"
            
            # å¦‚æœä¸æ˜¯é€šè¿‡ task_complete ç»“æŸçš„ï¼Œç”Ÿæˆæœ€ç»ˆå“åº”
            if not tool_call or tool_call.get("tool_name") != "task_complete":
                yield {
                    "type": "thinking",
                    "content": "\nğŸ¤” AIæ­£åœ¨æ€»ç»“...\n"
                }
                
                response = await self._generate_response(
                    message,
                    all_results,
                    model=model,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    top_p=top_p,
                    frequency_penalty=frequency_penalty,
                    presence_penalty=presence_penalty,
                    stream=True
                )
                
                # æ›´æ–°å¯¹è¯å†å²
                self.context["conversation_history"].append({
                    "role": "assistant",
                    "content": response
                })
                
                # è¿”å›æœ€ç»ˆå“åº”
                yield {
                    "type": "response",
                    "content": f"\n{response}\n"
                }
            
        except Exception as e:
            logger.error("Error in stream_message: %s", str(e), exc_info=True)
            yield {
                "type": "error",
                "content": f"\nâŒ å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯:\n{str(e)}\n"
            }
            
    def _format_step_result(self, step: Dict[str, Any], result: Dict[str, Any]) -> str:
        """Format step execution result as markdown.
        
        Args:
            step: Step definition
            result: Step execution result
            
        Returns:
            Formatted markdown string
        """
        if step['tool_name'] == 'knowledge_base':
            return self._format_knowledge_base_result(step, result)
        elif step['tool_name'] == 'email':
            return self._format_email_result(step, result)
        elif isinstance(result, str):
            return result
        else:
            return self._format_system_command_result(result)
    
    def _format_knowledge_base_result(self, step: Dict[str, Any], result: Dict[str, Any]) -> str:
        """Format knowledge base result as markdown.
        
        Args:
            step: Step definition
            result: Step execution result
            
        Returns:
            Formatted markdown string
        """
        operation = step['parameters'].get('operation')
        success = result.get("success", False)
        message = result.get("message", "")
        data = result.get("data", None)
        
        if not success:
            return f"**é”™è¯¯ï¼š** {message}\n"
            
        if operation == 'search':
            if isinstance(data, list):
                md = f"æ‰¾åˆ° {len(data)} æ¡ç›¸å…³çŸ¥è¯†ï¼š\n\n"
                for doc in data:
                    md += f"**æ–‡æ¡£ ID:** `{doc.get('id', 'N/A')}`\n"
                    md += f"**æ ‡é¢˜:** {doc.get('title', 'æ— æ ‡é¢˜')}\n"
                    md += f"**å†…å®¹:** \n```\n{doc.get('content', 'æ— å†…å®¹')}\n```\n"
                    md += f"**åˆ›å»ºæ—¶é—´:** {doc.get('created_at', 'N/A')}\n\n"
                return md
            return "æœç´¢ç»“æœæ ¼å¼é”™è¯¯\n\n"
            
        elif operation == 'create':
            if isinstance(data, dict):
                md = "æˆåŠŸåˆ›å»ºæ–‡æ¡£ï¼š\n\n"
                md += f"**æ–‡æ¡£ ID:** `{data.get('id', 'N/A')}`\n"
                md += f"**æ ‡é¢˜:** {data.get('title', 'æ— æ ‡é¢˜')}\n"
                md += f"**å†…å®¹:** \n```\n{data.get('content', 'æ— å†…å®¹')}\n```\n"
                md += f"**åˆ›å»ºæ—¶é—´:** {data.get('created_at', 'N/A')}\n\n"
                return md
            return "åˆ›å»ºæ–‡æ¡£æ ¼å¼é”™è¯¯\n\n"
            
        elif operation == 'update':
            if isinstance(data, dict):
                md = "æˆåŠŸæ›´æ–°æ–‡æ¡£ï¼š\n\n"
                md += f"**æ–‡æ¡£ ID:** `{data.get('id', 'N/A')}`\n"
                md += f"**æ ‡é¢˜:** {data.get('title', 'æ— æ ‡é¢˜')}\n"
                md += f"**å†…å®¹:** \n```\n{data.get('content', 'æ— å†…å®¹')}\n```\n"
                md += f"**æ›´æ–°æ—¶é—´:** {data.get('updated_at', 'N/A')}\n\n"
                return md
            return "æ›´æ–°æ–‡æ¡£æ ¼å¼é”™è¯¯\n\n"
            
        elif operation == 'delete':
            return f"æˆåŠŸåˆ é™¤æ–‡æ¡£\n\n"
            
        elif operation == 'get':
            if isinstance(data, dict):
                md = "è·å–åˆ°çš„æ–‡æ¡£ï¼š\n\n"
                md += f"**æ–‡æ¡£ ID:** `{data.get('id', 'N/A')}`\n"
                md += f"**æ ‡é¢˜:** {data.get('title', 'æ— æ ‡é¢˜')}\n"
                md += f"**å†…å®¹:** \n```\n{data.get('content', 'æ— å†…å®¹')}\n```\n"
                md += f"**åˆ›å»ºæ—¶é—´:** {data.get('created_at', 'N/A')}\n\n"
                return md
            return "è·å–æ–‡æ¡£æ ¼å¼é”™è¯¯\n\n"
            
        return f"æœªçŸ¥æ“ä½œç±»å‹ï¼š{operation}\n\n"
    
    def _format_email_result(self, step: Dict[str, Any], result: Dict[str, Any]) -> str:
        """Format email tool result as markdown.
        
        Args:
            step: Step definition
            result: Step execution result
            
        Returns:
            Formatted markdown string
        """
        action = step['parameters'].get('action')
        
        # è®°å½•åŸå§‹ç»“æœç”¨äºè°ƒè¯•
        logger.debug("Email result: %s", json.dumps(result, ensure_ascii=False))
        
        if action == 'list_emails':
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰ success å’Œ result å­—æ®µ
            if result.get('success') and isinstance(result.get('result', {}).get('emails'), list):
                emails = result['result']['emails']
                if not emails:
                    return "æ²¡æœ‰æ‰¾åˆ°ä»»ä½•é‚®ä»¶"
                
                md = f"æ‰¾åˆ° {len(emails)} å°é‚®ä»¶ï¼š\n\n"
                for email in emails:
                    md += "---\n"
                    message_id = email.get('message_id', 'N/A')
                    subject = email.get('subject', 'æ— ä¸»é¢˜')
                    sender = email.get('from', 'æœªçŸ¥')
                    date = email.get('date', 'æœªçŸ¥')
                    body = email.get('body', '')
                    
                    md += f"ğŸ“§ é‚®ä»¶ ID: `{message_id}`\n"
                    md += f"ğŸ“‘ ä¸»é¢˜: {subject}\n"
                    md += f"ğŸ‘¤ å‘ä»¶äºº: {sender}\n"
                    md += f"ğŸ“… æ—¥æœŸ: {date}\n"
                    
                    if body:
                        # å¦‚æœæ˜¯ HTML å†…å®¹ï¼Œå°è¯•æå–çº¯æ–‡æœ¬
                        if body.strip().startswith('<!DOCTYPE html') or body.strip().startswith('<html'):
                            # ç®€å•æå–æ–‡æœ¬ï¼Œå»é™¤ HTML æ ‡ç­¾
                            text_content = body.replace('</div>', '\n').replace('</p>', '\n')
                            for tag in ['<br />', '<br/>', '<br>', '\r\n', '\n\n']:
                                text_content = text_content.replace(tag, '\n')
                                
                            # ç§»é™¤æ‰€æœ‰ HTML æ ‡ç­¾
                            import re
                            text_content = re.sub(r'<[^>]+>', '', text_content)
                            
                            # æ¸…ç†ç©ºç™½è¡Œå’Œå¤šä½™ç©ºæ ¼
                            lines = [line.strip() for line in text_content.split('\n') if line.strip()]
                            text_content = '\n'.join(lines)
                            
                            # é™åˆ¶é¢„è§ˆé•¿åº¦
                            preview = text_content[:500] + ('...' if len(text_content) > 500 else '')
                        else:
                            preview = body[:500] + ('...' if len(body) > 500 else '')
                        
                        md += f"ğŸ“ å†…å®¹é¢„è§ˆ:\n```\n{preview}\n```\n"
                    
                    md += "\n"
                return md
            
            return "é‚®ä»¶åˆ—è¡¨è·å–å¤±è´¥æˆ–æ ¼å¼é”™è¯¯"
            
        elif action == 'delete_email':
            if result.get('success'):
                return "âœ… é‚®ä»¶å·²æˆåŠŸåˆ é™¤"
            else:
                error = result.get('message', 'æœªçŸ¥é”™è¯¯')
                return f"âŒ åˆ é™¤é‚®ä»¶å¤±è´¥ï¼š{error}"
        
        # å¦‚æœæ˜¯å…¶ä»–æ“ä½œæˆ–ç»“æœæ ¼å¼å®Œå…¨ä¸ç¬¦åˆé¢„æœŸï¼Œè¿”å›åŸå§‹ä¿¡æ¯
        return f"å·¥å…·è¿”å›ç»“æœï¼š\n```json\n{json.dumps(result, ensure_ascii=False, indent=2)}\n```"
    
    def _format_system_command_result(self, result: Dict[str, Any]) -> str:
        """Format system command result as markdown.
        
        Args:
            result: Command execution result
            
        Returns:
            Formatted markdown string
        """
        # ç›´æ¥è¿”å›åŸå§‹ç»“æœçš„JSONå­—ç¬¦ä¸²
        return json.dumps(result, ensure_ascii=False, indent=2)

    def _extract_tool_call(self, response: str) -> Optional[Dict[str, Any]]:
        """ä»æ¨¡å‹å“åº”ä¸­æå–å·¥å…·è°ƒç”¨ä¿¡æ¯
        
        Args:
            response: æ¨¡å‹çš„å“åº”æ–‡æœ¬
            
        Returns:
            å·¥å…·è°ƒç”¨ä¿¡æ¯å­—å…¸ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°å·¥å…·è°ƒç”¨åˆ™è¿”å›None
        """
        try:
            # å°è¯•æŸ¥æ‰¾JSONæ ¼å¼çš„å·¥å…·è°ƒç”¨
            # 1. æŸ¥æ‰¾```jsonå—
            if '```json' in response:
                json_blocks = response.split('```json')
                for block in json_blocks[1:]:  # è·³è¿‡ç¬¬ä¸€ä¸ªåˆ†å‰²ï¼ˆå‰å¯¼æ–‡æœ¬ï¼‰
                    json_str = block.split('```')[0].strip()
                    try:
                        tool_data = json.loads(json_str)
                        if isinstance(tool_data, dict) and 'tool_name' in tool_data:
                            return tool_data
                        elif isinstance(tool_data, list) and len(tool_data) > 0 and isinstance(tool_data[0], dict) and 'tool_name' in tool_data[0]:
                            return tool_data[0]
                    except json.JSONDecodeError:
                        continue
            
            # 2. æŸ¥æ‰¾```å—ï¼ˆå¯èƒ½æ˜¯å…¶ä»–ä»£ç å—æ ¼å¼ï¼‰
            if '```' in response:
                code_blocks = response.split('```')
                for i in range(1, len(code_blocks), 2):  # åªæ£€æŸ¥ä»£ç å—å†…å®¹
                    try:
                        tool_data = json.loads(code_blocks[i].strip())
                        if isinstance(tool_data, dict) and 'tool_name' in tool_data:
                            return tool_data
                        elif isinstance(tool_data, list) and len(tool_data) > 0 and isinstance(tool_data[0], dict) and 'tool_name' in tool_data[0]:
                            return tool_data[0]
                    except json.JSONDecodeError:
                        continue
            
            # 3. å°è¯•åœ¨æ•´ä¸ªå“åº”ä¸­æŸ¥æ‰¾JSONå¯¹è±¡
            # æŸ¥æ‰¾å¯èƒ½çš„JSONå¯¹è±¡å¼€å§‹å’Œç»“æŸä½ç½®
            start_pos = response.find('{')
            if start_pos != -1:
                # å°è¯•è§£æä»è¿™ä¸ªä½ç½®å¼€å§‹çš„JSON
                try:
                    # ä½¿ç”¨ç®€å•çš„æ‹¬å·åŒ¹é…æ¥æ‰¾åˆ°JSONå¯¹è±¡çš„ç»“æŸä½ç½®
                    brace_count = 0
                    end_pos = start_pos
                    for i in range(start_pos, len(response)):
                        if response[i] == '{':
                            brace_count += 1
                        elif response[i] == '}':
                            brace_count -= 1
                            if brace_count == 0:
                                end_pos = i + 1
                                break
                    
                    if end_pos > start_pos:
                        json_str = response[start_pos:end_pos]
                        tool_data = json.loads(json_str)
                        if isinstance(tool_data, dict) and 'tool_name' in tool_data:
                            return tool_data
                except (json.JSONDecodeError, IndexError):
                    pass
            
            # 4. æŸ¥æ‰¾æ•°ç»„å½¢å¼çš„JSON
            start_pos = response.find('[')
            if start_pos != -1:
                try:
                    # ä½¿ç”¨ç®€å•çš„æ‹¬å·åŒ¹é…æ¥æ‰¾åˆ°JSONæ•°ç»„çš„ç»“æŸä½ç½®
                    bracket_count = 0
                    end_pos = start_pos
                    for i in range(start_pos, len(response)):
                        if response[i] == '[':
                            bracket_count += 1
                        elif response[i] == ']':
                            bracket_count -= 1
                            if bracket_count == 0:
                                end_pos = i + 1
                                break
                    
                    if end_pos > start_pos:
                        json_str = response[start_pos:end_pos]
                        tool_data = json.loads(json_str)
                        if isinstance(tool_data, list) and len(tool_data) > 0 and isinstance(tool_data[0], dict) and 'tool_name' in tool_data[0]:
                            return tool_data[0]
                except (json.JSONDecodeError, IndexError):
                    pass
            
            return None
        except Exception as e:
            logger.error("ä»å“åº”ä¸­æå–å·¥å…·è°ƒç”¨å¤±è´¥: %s", str(e), exc_info=True)
            return None